{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HCE Predictive Policing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.8.2 (default, Apr 27 2020, 15:53:34) \n",
      "[GCC 9.3.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=8, micro=2, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('compas_scores_two_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3696\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Other                377\n",
       "Asian                 32\n",
       "Native American       18\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.race.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRATCH SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_df = data[['id', 'name','race','is_recid', 'two_year_recid']]\n",
    "fp_fn = cut_df[cut_df.is_recid != cut_df.two_year_recid]\n",
    "fp = cut_df[(cut_df.is_recid == 1)& (cut_df.two_year_recid==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1=len(cut_df[(cut_df.race=='African-American') & (cut_df.is_recid ==1)])/len(cut_df[(cut_df.race=='African-American') & (cut_df.two_year_recid ==0)])\n",
    "term2=len(cut_df[(cut_df.race=='Caucasian') & (cut_df.is_recid ==1)])/len(cut_df[(cut_df.race=='Caucasian') & (cut_df.two_year_recid ==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data[(data.race==group1) & (data.is_recid ==1) & (data.two_year_recid ==0)])\n",
    "g1_fp = len(cut_df[(cut_df.race=='African-American') & (cut_df.is_recid==1) & (cut_df.two_year_recid==0)])\n",
    "#len(cut_df[(cut_df.race=='Caucasian') & (cut_df.is_recid==1) & (cut_df.two_year_recid==0)])\n",
    "g1_tp = len(cut_df[(cut_df.race=='African-American') & (cut_df.is_recid==1)])\n",
    "g1_tn = len(cut_df[(cut_df.race=='African-American') & (cut_df.is_recid==0) & (cut_df.two_year_recid==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1660"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 2036)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_fp, g1_tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week of May 17:\n",
    "Translating FRGS, FDR, FPR metrics into code and placing them in a jupyter notebook which will be the base of our project. We want these metrics to be attached to different stats papers and fully functional. Should take in the ProPublica data and output a figure. These metrics will be the backbone of the second part of the project, which talks about different ways to assess the fairness of the ProPublica/Northpointe debate, and brings in statistician’s own concepts of fairness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parity Metrics\n",
    "Reference: https://stats.stackexchange.com/questions/336455/fpr-false-positive-rate-vs-fdr-false-discovery-rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPGS Parity \n",
    "### Motivating Idea: What are your changes of being wrongly denied bail just given your race? \n",
    "AKA, Given you are of a certain group, what is the probability of your true label being different from your predicted label? We use this metric when we are trying to ensure predictive equity **for everyone without regard for actual outcome**.\n",
    "$$ P(\\hat{Y} = 1, {Y} = 0 | G) $$\n",
    "\n",
    "We can also see this as **False Positive Group Selection** Parity. Aequitas describes this as examining the number of entities of the group with $\\hat{Y} = 1$ and ${Y} = 0 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpgs_parity(data, group1, group2):\n",
    "    '''\n",
    "    Given two groups for which we'd like to compare the False Positive\n",
    "    Group Selection parity, generate a ratio of the counts of Y_hat = 1\n",
    "    and Y=0 for each group.\n",
    "    '''\n",
    "    # Group 1 Count Y_hat\n",
    "    g1_yhat = len(data[(data.race==group1) & (data.is_recid ==1)])\n",
    "    # Group 1 Count Y\n",
    "    g1_y = len(data[(data.race==group1) & (data.two_year_recid ==0)])\n",
    "    # Group 2 Count Y_hat\n",
    "    g2_yhat = len(data[(data.race==group2) & (data.is_recid ==1)])\n",
    "    # Group  2 Count Y                                                            \n",
    "    g2_y = len(data[(data.race==group2) & (data.two_year_recid ==0)]) \n",
    "    \n",
    "    return g1_yhat/g2_yhat, g1_y/g2_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23902439024390243, 0.2721774193548387)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpgs_parity(cut_df, 'African-American', 'Caucasian')\n",
    "fpgs_parity(cut_df, 'Hispanic', 'Caucasian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR Parity\n",
    "### Motivating Idea: Among people denied bail, what are the chances you're innocent given your race? \n",
    "AKA, Given you are of a certain group and predicted to be denied bail, what is the probability that your true label is 0? We use this metric when trying to ensure predictive equity among people **for whom intervention is taken.** This means intervening for those denied bail to make sure they were predicted accurately. \n",
    "$$ P({Y} = 0 | G, \\hat{Y} = 1) $$\n",
    "\n",
    "\n",
    "We can also see this as **False Discovery Rate** Parity. Aequitas describes this as examining the false positives of a group within the predicted positives of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr_parity(data, group1, group2):\n",
    "    '''\n",
    "    Given two groups for which we'd like to compare the False Discovery \n",
    "    Rate parity, generate a ratio of the probabilities as specified above.\n",
    "    \n",
    "    We find this by calculating False Positives over Total Predicted Positives.  \n",
    "    '''\n",
    "    # Group 1 False Positive Count\n",
    "    g1_false_predictions = len(data[(data.race==group1) & (data.is_recid ==1) & (data.two_year_recid ==0)])\n",
    "    # Group 1 Total Positive Count\n",
    "    g1_total_predictions = len(data[(data.race==group1) & (data.is_recid==1)])\n",
    "    # Group 2 False Positive Count\n",
    "    g2_false_predictions = len(data[(data.race==group2) & (data.is_recid ==1) & (data.two_year_recid ==0)])\n",
    "    # Group 2 Total Positive Count\n",
    "    g2_total_predictions = len(data[(data.race==group2) & (data.is_recid==1)])\n",
    "\n",
    "    g1_fdr = g1_false_predictions/g1_total_predictions\n",
    "    g2_fdr = g2_false_predictions/g2_total_predictions\n",
    "    \n",
    "    return g1_fdr, g2_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06630648330058939, 0.0575609756097561)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdr_parity(cut_df, 'African-American', 'Caucasian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPR Parity\n",
    "\n",
    "### Motivating Idea: Among people who **should** be granted bail, what are the chances you were denied bail given your race?\n",
    "AKA, Given your are of a certain group and your true label is 0, what is the probability that you were predicted to be denied bail? We use this metric when trying to ensure predictive equity for groups **that do not warrant intervention.** This means \n",
    "$$ P(\\hat{Y} = 1 | G, {Y} = 0) $$\n",
    "\n",
    "\n",
    "We can also see this as **False Positive Rate** Parity. Aequitas describes this as examining the fraction of false positives of a group within the predicted positive of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr_parity(data, group1, group2):\n",
    "    '''\n",
    "    Given two groups for which we'd like to compare the False Positive\n",
    "    Rate parity, generate a ratio of the probabilities as specified above.\n",
    "    \n",
    "    We find this by calculating False Positives over False Positives and True Negatives. \n",
    "    '''\n",
    "    # Group 1 False Positive Count\n",
    "    g1_false_positives = len(data[(data.race==group1) & (data.is_recid ==1) & (data.two_year_recid ==0)])\n",
    "    # Group 1 True Negative Count \n",
    "    g1_tn = len(data[(data.race==group1) & (data.is_recid==0) & (data.two_year_recid==0)])\n",
    "    # Group 2 False Positive Count\n",
    "    g2_false_positives= len(data[(data.race==group2) & (data.is_recid ==1) & (data.two_year_recid ==0)])\n",
    "    # Group 2 True Negative Count\n",
    "    g2_tn = len(data[(data.race==group2) & (data.is_recid==0) & (data.two_year_recid==0)])\n",
    "    \n",
    "    g1_fpr = g1_false_positives / (g1_false_positives+g1_tn)\n",
    "    g2_fpr = g2_false_positives / (g2_false_positives+g2_tn)\n",
    "\n",
    "    return g1_fpr, g2_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07520891364902507, 0.0396505376344086)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_parity(cut_df, 'African-American', 'Caucasian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
